{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시맨틱 검색 - Semantic Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시맨틱 검색 (Semantic Search)\n",
    "\n",
    "오픈서치의 시맨틱 검색은 검색 쿼리의 의미를 이해하고, 그에 따라 가장 관련성 높은 결과를 사용자에게 제공하는 기능입니다. 이는 전통적인 키워드 기반 검색과 달리, 검색 쿼리의 맥락과 의미를 분석하여 보다 정확하고 관련성 높은 검색 결과를 제공합니다. 예를 들어 \"아마존\"이라는 단어가 상품명인지, 회사명인지, 아니면 지역명인지 등 쿼리의 의미를 파악하여 그에 맞는 검색 결과를 제공합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 검색(Neural Search)\n",
    "\n",
    "수년 동안 고객들은 OpenSearch k-NN을 기반으로 시맨틱 검색 애플리케이션을 구축하기 위해서는 텍스트 임베딩 모델을 검색 및 수집 파이프라인에 통합하기 위해 추가적인 미들웨어를 구축해야 하는 부담이 있었습니다. 이제 Amazon SageMaker와 Amazon Bedrock와의 통합을 통해 신경망 검색을 강화하며 클러스터에서 실행되는 시맨틱 검색 파이프라인을 지원할 수 있습니다.\n",
    "\n",
    "신경망 검색은 텍스트를 벡터로 변환하고 인덱싱 시간과 검색 시간 모두에서 벡터 검색을 용이하게 합니다. 인덱싱 중에 신경망 검색은 문서 텍스트를 벡터 임베딩으로 변환하고 텍스트와 그 벡터 임베딩을 모두 벡터 인덱스에 인덱싱합니다. 신경망 쿼리를 사용하는 경우 신경망 검색은 쿼리 텍스트를 벡터 임베딩으로 변환하고, 벡터 검색을 사용하여 쿼리와 문서 임베딩을 비교한 다음 가장 가까운 결과를 반환합니다.\n",
    "\n",
    "문서를 인덱스에 인제스트하기 전에 문서는 기계 학습(ML) 모델을 통과하게 되며, 이 모델은 문서 필드에 대한 벡터 임베딩을 생성합니다. 검색 요청을 보내면 쿼리 텍스트나 이미지도 ML 모델을 통과하여 해당 벡터 임베딩을 생성합니다. 그런 다음 신경망 검색이 임베딩에 대한 벡터 검색을 수행하고 일치하는 문서를 반환합니다.\n",
    "\n",
    "신경망 검색을 사용하면 OpenSearch API를 통해 인간의 언어로 검색 쿼리를 실행하고, Amazon SageMaker에서 호스팅되거나 Amazon Bedrock에서 관리하는 텍스트 임베딩을 통해 의미론적 이해와 유사성을 고려한 텍스트 임베딩을 사용하여 더 정확한 결과를 제공할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전준비\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 패키지를 설치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q requests\n",
    "!pip install -q requests-aws4auth\n",
    "!pip install -q opensearch-py\n",
    "!pip install -q tqdm\n",
    "!pip install -q boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "키워드 검색 단계에서와 마찬가지로 데이터를 준비합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>plot</th>\n",
       "      <th>main_act</th>\n",
       "      <th>supp_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>변호인</td>\n",
       "      <td>드라마</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.18</td>\n",
       "      <td>8.99</td>\n",
       "      <td>94574</td>\n",
       "      <td>198 년대 초 부산. 빽 없고, 돈 없고, 가방끈도 짧은 세무 변호사 송우석(송강...</td>\n",
       "      <td>송강호|김영애|오달수|곽도원|임시완</td>\n",
       "      <td>송영창|정원중|조민기|이항나|이성민|차은재|차광수|한기중|심희섭|조완기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어벤져스: 엔드게임</td>\n",
       "      <td>액션|SF</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.24</td>\n",
       "      <td>9.38</td>\n",
       "      <td>68923</td>\n",
       "      <td>인피니티 워 이후 절반만 살아남은 지구 마지막 희망이 된 어벤져스 먼저 떠난 그들을...</td>\n",
       "      <td>로버트 다우니 주니어|크리스 에반스|크리스 헴스워스|마크 러팔로|스칼렛 요한슨|제레...</td>\n",
       "      <td>베네딕트 컴버배치|조 샐다나|크리스 프랫|채드윅 보스만|톰 홀랜드|안소니 마키|기네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>명량</td>\n",
       "      <td>액션|드라마</td>\n",
       "      <td>2014</td>\n",
       "      <td>7.30</td>\n",
       "      <td>8.44</td>\n",
       "      <td>66953</td>\n",
       "      <td>1597년 임진왜란 6년, 오랜 전쟁으로 인해 혼란이 극에 달한 조선. 무서운 속도...</td>\n",
       "      <td>최민식|류승룡|조진웅</td>\n",
       "      <td>진구|이정현|김명곤|권율|노민우|김태훈|오타니 료헤이|이승준|김강일|박보검|이해영|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>부산행</td>\n",
       "      <td>액션|스릴러</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.20</td>\n",
       "      <td>8.00</td>\n",
       "      <td>59184</td>\n",
       "      <td>정체불명의 바이러스가 전국으로 확산되고 대한민국 긴급재난경보령이 선포된 가운데, 열...</td>\n",
       "      <td>공유|정유미|마동석|김수안|김의성|최우식|안소희</td>\n",
       "      <td>최귀화|정석용|예수정|박명신|장혁진</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>신과함께-죄와 벌</td>\n",
       "      <td>판타지|드라마</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.20</td>\n",
       "      <td>7.83</td>\n",
       "      <td>58124</td>\n",
       "      <td>저승 법에 의하면, 모든 인간은 사후 49일 동안 7번의 재판을 거쳐야만 한다. 살...</td>\n",
       "      <td>하정우|차태현|주지훈|김향기|김동욱|마동석</td>\n",
       "      <td>오달수|임원희|디오|이준혁|예수정|장광|정해균|김수안|남일우|정지훈</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title    genre  year   date  rating  vote_count  \\\n",
       "0         변호인      드라마  2013  12.18    8.99       94574   \n",
       "1  어벤져스: 엔드게임    액션|SF  2019   4.24    9.38       68923   \n",
       "2          명량   액션|드라마  2014   7.30    8.44       66953   \n",
       "3         부산행   액션|스릴러  2016   7.20    8.00       59184   \n",
       "4   신과함께-죄와 벌  판타지|드라마  2017  12.20    7.83       58124   \n",
       "\n",
       "                                                plot  \\\n",
       "0  198 년대 초 부산. 빽 없고, 돈 없고, 가방끈도 짧은 세무 변호사 송우석(송강...   \n",
       "1  인피니티 워 이후 절반만 살아남은 지구 마지막 희망이 된 어벤져스 먼저 떠난 그들을...   \n",
       "2  1597년 임진왜란 6년, 오랜 전쟁으로 인해 혼란이 극에 달한 조선. 무서운 속도...   \n",
       "3  정체불명의 바이러스가 전국으로 확산되고 대한민국 긴급재난경보령이 선포된 가운데, 열...   \n",
       "4  저승 법에 의하면, 모든 인간은 사후 49일 동안 7번의 재판을 거쳐야만 한다. 살...   \n",
       "\n",
       "                                            main_act  \\\n",
       "0                                송강호|김영애|오달수|곽도원|임시완   \n",
       "1  로버트 다우니 주니어|크리스 에반스|크리스 헴스워스|마크 러팔로|스칼렛 요한슨|제레...   \n",
       "2                                        최민식|류승룡|조진웅   \n",
       "3                         공유|정유미|마동석|김수안|김의성|최우식|안소희   \n",
       "4                            하정우|차태현|주지훈|김향기|김동욱|마동석   \n",
       "\n",
       "                                            supp_act  \n",
       "0            송영창|정원중|조민기|이항나|이성민|차은재|차광수|한기중|심희섭|조완기  \n",
       "1  베네딕트 컴버배치|조 샐다나|크리스 프랫|채드윅 보스만|톰 홀랜드|안소니 마키|기네...  \n",
       "2  진구|이정현|김명곤|권율|노민우|김태훈|오타니 료헤이|이승준|김강일|박보검|이해영|...  \n",
       "3                                최귀화|정석용|예수정|박명신|장혁진  \n",
       "4              오달수|임원희|디오|이준혁|예수정|장광|정해균|김수안|남일우|정지훈  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "df = pd.read_csv(\"./data/sample.csv\", low_memory=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 스키마를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 필드에 영화에 대한 전체적인 정보를 담기 위해 전체 컬럼을 모두 조합한 `text` 컬럼을 추가합니다. 이 `text` 필드는 이후 ingest pipeline에 의해 임베딩될 필드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "data_path = './data'\n",
    "with open(f'{data_path}/tables.json', 'rb') as ofp:\n",
    "    meta = json.load(ofp)\n",
    "data = meta[0]\n",
    "\n",
    "data = [i for i in meta if i['db_id'] == 'department_store']\n",
    "\n",
    "data  = data[0]    \n",
    "columns = data[\"column_names_original\"]\n",
    "col_df = pd.DataFrame(columns).iloc[1:]\n",
    "col_df.rename(columns={0: 'table_idx', 1: 'col_name'}, inplace=True)\n",
    "col_df\n",
    "\n",
    "types_df = pd.DataFrame(data[\"column_types\"]).iloc[1:]\n",
    "types_df.rename(columns={0: 'type'}, inplace=True)\n",
    "types_df\n",
    "\n",
    "merged_col = pd.concat([col_df, types_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables_df = pd.DataFrame(data[\"table_names_original\"])\n",
    "tables_df.reset_index(inplace=True)\n",
    "tables_df.columns = ['table_idx', 'table_name']\n",
    "\n",
    "meta = pd.merge(tables_df, merged_col, on=['table_idx'])\n",
    "meta = meta.drop(columns=['table_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>col_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addresses</td>\n",
       "      <td>address_id</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Addresses</td>\n",
       "      <td>address_details</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  table_name         col_name    type\n",
       "0  Addresses       address_id  number\n",
       "1  Addresses  address_details    text"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## table 단위로 row를 생성한다면 아래와 같이 늘리는 작업이 필요함 \n",
    "## 그런데 단순 col name말고 type, description까지 생긴다고 보면 그렇게는 못할지도 \n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def create_text(row, max_len=509):\n",
    "#     text = \"\"\n",
    "#     for col, val in row.items():\n",
    "#         text += f\"{col}: {val},\"\n",
    "#     if len(text) > max_len:\n",
    "#         text = text[:max_len] + \"...\"\n",
    "\n",
    "#     # print(text.rstrip(\"\\n\"))\n",
    "#     return text.rstrip()\n",
    "\n",
    "\n",
    "# # Assuming your DataFrame is called 'df'\n",
    "# df[\"text\"] = df.apply(create_text, axis=1)\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 줄거리의 길이가 512가 넘는 레코드가 있는지 확인합니다\n",
    "# def find_long_plot_items(df):\n",
    "#     long_plot_items = df[df[\"text\"].str.len() > 512]\n",
    "#     return long_plot_items\n",
    "\n",
    "\n",
    "# find_long_plot_items(df).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenSearch 도메인에 연결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cfn_outputs(stackname, cfn):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)[\"Stacks\"][0][\"Outputs\"]:\n",
    "        outputs[output[\"OutputKey\"]] = output[\"OutputValue\"]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search-opensearch-workshop-ashew5agtjkgsyxprzgu2m2oua.us-west-2.es.amazonaws.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3, json\n",
    "\n",
    "\n",
    "region_name = \"us-west-2\"\n",
    "\n",
    "cfn = boto3.client(\"cloudformation\", region_name)\n",
    "kms = boto3.client(\"secretsmanager\", region_name)\n",
    "\n",
    "stackname = \"opensearch-workshop\"\n",
    "cfn_outputs = get_cfn_outputs(stackname, cfn)\n",
    "\n",
    "aos_credentials = json.loads(\n",
    "    kms.get_secret_value(SecretId=cfn_outputs[\"OpenSearchSecret\"])[\"SecretString\"]\n",
    ")\n",
    "\n",
    "aos_host = cfn_outputs[\"OpenSearchDomainEndpoint\"]\n",
    "aos_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "auth = (aos_credentials[\"username\"], aos_credentials[\"password\"])\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts=[{\"host\": aos_host, \"port\": 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 임베딩을 위한 Ingest Pipeline 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 배포 과정을 참고하여 배포된 모델의 ID를 확인하고 아래와 같이 변수에 초기화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DTDeTJAB3Hj2edbFglKU'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "search_model = {\"query\": {\"match\": {\"name\": \"OpenSearch-Cohere\"}}, \"size\": 10}\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://\" + aos_host + \"/_plugins/_ml/models/_search\", auth=auth, json=search_model\n",
    ")\n",
    "model_info = json.loads(response.text)\n",
    "model_id = model_info[\"hits\"][\"hits\"][0][\"_id\"]\n",
    "model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인제스트 파이프라인 생성\n",
    "\n",
    "영화의 줄거리 정보를 가진 특정 필드(\"plot\")에 대한 벡터 임베딩을 생성하는 파이프라인을 설정합니다. 이러한 임베딩은 검색 인덱스 필드(\"vector_field\")에 저장되며, 효율적인 유사성 검색 및 검색 작업에 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = {\n",
    "    \"description\": \"Text to Sql Task - OpenSearch-cohere-060124084807\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": model_id,\n",
    "                \"field_map\": {\n",
    "                    \"text\": \"vector_field\",\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "pipeline_id = \"text2sql_meta_data\"\n",
    "# aos_client.ingest.delete_pipeline(id=pipeline_id)\n",
    "aos_client.ingest.put_pipeline(id=pipeline_id, body=pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스 생성\n",
    "\n",
    "movie_semantic 인덱스를 생성합니다. 아래 세팅 및 맵핑 정보 중 중요한 것은 다음과 같습니다.\n",
    "\n",
    "-   index.knn: KNN 검색을 위해 True로 설정합니다.\n",
    "-   default_pipeline: 위 단계에서 생성한 pipeline_id를 제공합니다.\n",
    "-   index.knn.space_type: 임베딩 벡터끼리의 유사도를 파악할 때 사용할 알고리즘을 cosinesimil로 지정합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>col_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addresses</td>\n",
       "      <td>address_id</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Addresses</td>\n",
       "      <td>address_details</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  table_name         col_name    type\n",
       "0  Addresses       address_id  number\n",
       "1  Addresses  address_details    text"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'rag_semantic_ver2'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"rag_semantic_ver2\"\n",
    "\n",
    "# aos_client.indices.delete(index=index_name)\n",
    "\n",
    "rag_semantic = {\n",
    "    \"settings\": {\n",
    "        \"max_result_window\": 15000,\n",
    "        \"analysis\": {\"analyzer\": {\"analysis-nori\": {\"type\": \"nori\", \"stopwords\": \"_korean_\"}}},\n",
    "        \"index.knn\": True,\n",
    "        \"default_pipeline\": pipeline_id,\n",
    "        \"index.knn.space_type\": \"l2\",\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"table_name\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"col_name\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"type\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                \"method\": {\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"faiss\"},\n",
    "                \"store\": True,\n",
    "            },\n",
    "\n",
    "        }\n",
    "    },\n",
    "}\n",
    "aos_client.indices.create(index=index_name, body=rag_semantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 인제스트\n",
    "\n",
    "키워드 검색과 동일하게 데이터를 인제스트합니다. 위 단계에서 인덱스를 생성할 때 INGEST PIPELINE을 설정했기 때문에 직접 임베딩 모델을 호출하여 데이터를 벡터로 변환하지 않아도 됩니다. 단, 데이터가 인제스트될 때 임베딩 모델을 호출해야 하는 단계가 있기 때문에 parallel_bulk의 병렬도가 높으면 에러가 발생할 있습니다. 여기서는 `thread_count`와 `queue_size`를 각각 1로 낮춰줍니다. 이 단계가 완료되는데는 약 4~5분 정도 소요됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from opensearchpy import helpers\n",
    "\n",
    "json_data = meta.to_json(orient=\"records\", lines=True)\n",
    "docs = json_data.split(\"\\n\")[:-1]  # To remove the last empty line\n",
    "\n",
    "\n",
    "def _generate_data():\n",
    "    for doc in docs:\n",
    "        yield {\"_index\": index_name, \"_source\": doc}\n",
    "\n",
    "\n",
    "succeeded = []\n",
    "failed = []\n",
    "for success, item in helpers.parallel_bulk(\n",
    "    aos_client, actions=_generate_data(), chunk_size=10, thread_count=1, queue_size=1\n",
    "):\n",
    "    if success:\n",
    "        succeeded.append(item)\n",
    "    else:\n",
    "        failed.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 인제스트가 잘 마무리되었는지 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 56, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Refresh the index to make the changes visible\n",
    "aos_client.indices.refresh(index=index_name)\n",
    "\n",
    "count = aos_client.count(index=index_name)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 검색과 시맨틱 검색 결과 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 키워드 검색을 위한 함수 생성\n",
    "\n",
    "키워드 단계에서 정의한 키워드 검색 함수와 동일한 함수를 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keyword_search(query_text):\n",
    "    query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": {\"excludes\": [\"text\", \"vector_field\"]},\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query_text,\n",
    "                \"fields\": [\"table_name\", \"col_name\"],\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, body=query)\n",
    "\n",
    "    query_result = []\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        row = [\n",
    "            hit[\"_score\"],\n",
    "            hit[\"_source\"][\"table_name\"],\n",
    "            hit[\"_source\"][\"col_name\"],\n",
    "            hit[\"_source\"][\"type\"],            \n",
    "        ]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(\n",
    "        data=query_result, columns=[\"_score\", \"table_name\", \"col_name\", \"type\"]\n",
    "    )\n",
    "    display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시맨팀 검색을 위한 함수 생성\n",
    "\n",
    "뉴럴 검색을 위한 함수를 생성합니다. 주목해야할 부분은 다음과 같습니다.\n",
    "\n",
    "1. **`\"_source\": {\"excludes\": [\"vector_field\"]}`**: 검색 결과에서 **`vector_field`** 필드를 제외한 모든 필드를 반환합니다. 이는 벡터 데이터가 크기 때문에 전송 비용을 줄이기 위함입니다.\n",
    "2. **`\"query\": { ... }`**: 실제 검색 쿼리를 정의합니다.\n",
    "3. **`\"neural\": { ... }`**: 벡터 검색을 수행하기 위한 쿼리 유형입니다.\n",
    "4. **`\"vector_field\": \"vector_field_name\"`**: 벡터 데이터가 저장된 필드 이름입니다.\n",
    "5. **`\"query_text\": query_text`**: 검색할 텍스트 쿼리입니다.\n",
    "6. **`\"model_id\": model_id`**: 벡터 임베딩을 생성하는 데 사용된 모델의 ID입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query_text):\n",
    "    query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": {\"excludes\": [\"text\", \"vector_field\"]},\n",
    "        \"query\": {\n",
    "            \"neural\": {\"vector_field\": {\"query_text\": query_text, \"model_id\": model_id, \"k\": 10}},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, body=query)\n",
    "\n",
    "    query_result = []\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        row = [\n",
    "            hit[\"_score\"],\n",
    "            hit[\"_source\"][\"table_name\"],\n",
    "            hit[\"_source\"][\"col_name\"],\n",
    "            hit[\"_source\"][\"type\"],            \n",
    "        ]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(\n",
    "        data=query_result, columns=[\"_score\", \"table_name\", \"col_name\", \"type\"]\n",
    "    )\n",
    "    display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 비교\n",
    "\n",
    "자연어 기반의 쿼리를 작성하고 키워드 검색과 시맨틱 검색의 결과를 비교해봅니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Product_Suppliers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>table_name</th>\n",
       "      <th>col_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.367124</td>\n",
       "      <td>Product_Suppliers</td>\n",
       "      <td>product_id</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.159484</td>\n",
       "      <td>Product_Suppliers</td>\n",
       "      <td>date_supplied_from</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.079442</td>\n",
       "      <td>Product_Suppliers</td>\n",
       "      <td>supplier_id</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>Product_Suppliers</td>\n",
       "      <td>total_amount_purchased</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.481604</td>\n",
       "      <td>Product_Suppliers</td>\n",
       "      <td>date_supplied_to</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.481604</td>\n",
       "      <td>Product_Suppliers</td>\n",
       "      <td>total_value_purchased</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _score         table_name                col_name    type\n",
       "0  2.367124  Product_Suppliers              product_id  number\n",
       "1  2.159484  Product_Suppliers      date_supplied_from    time\n",
       "2  2.079442  Product_Suppliers             supplier_id  number\n",
       "3  1.791759  Product_Suppliers  total_amount_purchased    text\n",
       "4  1.481604  Product_Suppliers        date_supplied_to    time\n",
       "5  1.481604  Product_Suppliers   total_value_purchased  number"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keyword_search(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>table_name</th>\n",
       "      <th>col_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_score, table_name, col_name, type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "semantic_search(query_text)\n",
    "# print(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- semantic search는 아무것도 나오지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순히 테이블을 때려 박는 게 아니라, 테이블에 대한 정보또한 llm으로 생성할 필요가 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
