{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q requests\n",
    "!pip install -q requests-aws4auth\n",
    "!pip install -q opensearch-py\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"faiss-cpu\" --quiet\n",
    "!pip install langchain --quiet\n",
    "!pip install jq --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain.docstore.document import Document\n",
    "import json\n",
    "import re\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from functools import reduce\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "data_path = './data'\n",
    "with open(f'{data_path}/tables.json', 'rb') as ofp:\n",
    "    meta = json.load(ofp)\n",
    "data = meta[0]\n",
    "\n",
    "data = [i for i in meta if i['db_id'] == 'department_store']\n",
    "\n",
    "data  = data[0]    \n",
    "columns = data[\"column_names_original\"]\n",
    "col_df = pd.DataFrame(columns).iloc[1:]\n",
    "col_df.rename(columns={0: 'table_idx', 1: 'col_name'}, inplace=True)\n",
    "col_df\n",
    "\n",
    "types_df = pd.DataFrame(data[\"column_types\"]).iloc[1:]\n",
    "types_df.rename(columns={0: 'type'}, inplace=True)\n",
    "types_df\n",
    "\n",
    "merged_col = pd.concat([col_df, types_df], axis=1)\n",
    "\n",
    "tables_df = pd.DataFrame(data[\"table_names_original\"])\n",
    "tables_df.reset_index(inplace=True)\n",
    "tables_df.columns = ['table_idx', 'table_name']\n",
    "\n",
    "meta = pd.merge(tables_df, merged_col, on=['table_idx'])\n",
    "meta = meta.drop(columns=['table_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"text2sql\"\n",
    "DB_FAISS_PATH = './vectorstore/db_faiss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "bedrock_region = athena_region = boto3.session.Session().region_name\n",
    "retry_config = Config(retries = {'max_attempts': 100})\n",
    "session = boto3.Session(region_name=bedrock_region)\n",
    "bedrock = session.client('bedrock-runtime', region_name=bedrock_region, config=retry_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def ask_llm(question):\n",
    "\n",
    "    body = json.dumps({\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"temperature\" : 0.1,\n",
    "                \"top_p\": 0.5,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": question},\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            }) \n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, \n",
    "        modelId=bedrock_model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json') #payload를 Bedrock으로 전송\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    llm_output = response_body.get(\"content\")[0].get(\"text\")\n",
    "    return llm_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new docs with the right metadata we need for indexing\n",
    "def create_docs_with_correct_metadata(documents):\n",
    "    # We are going to return a list of new documents\n",
    "    new_docs = []\n",
    "\n",
    "    # For each document\n",
    "    for doc in documents:\n",
    "        # Get it's metadata and contents\n",
    "        metadata = doc.metadata\n",
    "        contents = json.loads(doc.page_content)\n",
    "\n",
    "        # Now calculate the new metadata that we want to add\n",
    "        new_metadata = {\n",
    "            \"tableName\": contents[\"tableName\"],\n",
    "            \"question\": contents[\"question\"],\n",
    "            \"tableSchema\": contents[\"tableSchema\"],\n",
    "        }\n",
    "\n",
    "        # Print out the new metadata for our documents\n",
    "        # print(new_metadata)\n",
    "\n",
    "        new_docs.append(\n",
    "            Document(page_content=new_metadata[\"question\"], metadata=new_metadata)\n",
    "        )\n",
    "\n",
    "    return new_docs\n",
    "\n",
    "def load_json_file(filename):\n",
    "    loader = JSONLoader(file_path=filename, jq_schema=\".[]\", text_content=False)\n",
    "\n",
    "    # This is our internal Langchain document data structure\n",
    "    docs = loader.load()\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function asks the LLM to inspect a table schema, generate some questions which could be answered\n",
    "# by that schema, and then it stores those questions to file, loads them all into a single vectorDB\n",
    "def add_new_table(schema, table_name, is_incremental, bedrock_embeddings):\n",
    "    \"\"\"\n",
    "    :schema         :   \n",
    "    :table_name     :\n",
    "    :model_id       :\n",
    "    :is_incremental :\n",
    "    \"\"\"\n",
    "    print(f\"Adding table {table_name} with schema {schema}\")\n",
    "    \n",
    "    question = f\"\"\"\n",
    "    \\n\\nHuman: \n",
    "    only return the a bulleted numbered list of unique and detailed questions that could be answered by this table called {table_name} with schema:\n",
    "    {schema}.\n",
    "    Instructions:\n",
    "        Use natural language descriptions only.\n",
    "        Do not use SQL.\n",
    "        Produced a varied list of questions, but the questions should be unique and detailed.\n",
    "        The questions should be in a format that is easy to understand and answer.\n",
    "        Ask about as much of the information in the table as possible.\n",
    "        You can ask about more than one aspect of the data at a time.\n",
    "        Qustions should begin with, 'What', 'Which', 'How', 'When' or 'Can'. Use variable names. \n",
    "        The questions should use relevant buisness vocabularly and terminology only. \n",
    "        Do not use column names in your output - use relevant natural language descriptions only. \n",
    "        Do not output any numeric values.\n",
    "        Output questions starting with bulleted numbered list. \n",
    "         \n",
    "        \\n Questions: 1.\n",
    "        \\n Assistant:\n",
    "        \"\"\"\n",
    "       \n",
    "    answer = ask_llm(question)\n",
    "    os.makedirs('./data/rag', exist_ok=True)\n",
    "    question_list_filename = f\"./data/rag/questionList{table_name}.json\"\n",
    "\n",
    "    # # Get rid of anything before the 1.\n",
    "    # if re.match(r\"^[^\\d+]\\. \", answer) and re.search(r\"\\d+\\. \", answer):\n",
    "    #     answer = \"1. \" + answer.split(\"1. \")[1]\n",
    "    # else:\n",
    "    #     answer = \"1. \" + answer\n",
    "\n",
    "    print(\n",
    "        f\"Writing questions to {question_list_filename}, with schema {schema}, with table name {table_name} and answer {answer}.\\n\\n\"\n",
    "    )\n",
    "\n",
    "    write_questions_to_file(question_list_filename, table_name, schema, answer)\n",
    "\n",
    "    docs = load_json_file(question_list_filename)\n",
    "    docs = create_docs_with_correct_metadata(docs)\n",
    "    new_questions = FAISS.from_documents(docs, bedrock_embeddings)\n",
    "    db_exists = True if os.path.exists(f\"{DB_FAISS_PATH}/index.faiss\") else False\n",
    "    # Add new tables\n",
    "    if is_incremental and db_exists:\n",
    "            question_db = FAISS.load_local(DB_FAISS_PATH, bedrock_embeddings, allow_dangerous_deserialization=True)\n",
    "            question_db.merge_from(new_questions)\n",
    "            question_db.save_local(DB_FAISS_PATH)\n",
    "\n",
    "    # Load for the first time\n",
    "    else:\n",
    "        print(f\"is_incremental set to {str(is_incremental)} and/or no vector db found. Creating...\")\n",
    "        new_questions.save_local(DB_FAISS_PATH)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_questions_to_file(question_list_filename, table_name, table_schema, answer):\n",
    "    data_list = []\n",
    "    question_list_obj = answer\n",
    "    questions_list = question_list_obj.splitlines()\n",
    "    # Open the file in write mode\n",
    "    with open(question_list_filename, mode=\"w\", newline=\"\") as file:\n",
    "        for question in questions_list:\n",
    "\n",
    "            # Skip if it doesn't really have a question\n",
    "            if \"?\" not in question:\n",
    "                continue\n",
    "\n",
    "            questionSplit = re.split(r\"\\d{1,5}.||. ||- \", question, maxsplit=1)\n",
    "            question = questionSplit[1]\n",
    "            data = {\n",
    "                \"tableName\": table_name,\n",
    "                \"question\": question,\n",
    "                \"tableSchema\": table_schema.lstrip(\" \"),\n",
    "            }\n",
    "            data_list.append(data)\n",
    "\n",
    "        json.dump(data_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from functools import reduce\n",
    "bedrock_embeddings = BedrockEmbeddings(client=bedrock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('address_id|address_details', 'Addresses')\n",
      "('customer_id|address_id|date_from|date_to', 'Customer_Addresses')\n",
      "('order_id|customer_id|order_status_code|order_date', 'Customer_Orders')\n",
      "('customer_id|payment_method_code|customer_code|customer_name|customer_address|customer_phone|customer_email', 'Customers')\n",
      "('dept_store_chain_id|dept_store_chain_name', 'Department_Store_Chain')\n",
      "('dept_store_id|dept_store_chain_id|store_name|store_address|store_phone|store_email', 'Department_Stores')\n",
      "('department_id|dept_store_id|department_name', 'Departments')\n",
      "('order_item_id|order_id|product_id', 'Order_Items')\n",
      "('product_id|supplier_id|date_supplied_from|date_supplied_to|total_amount_purchased|total_value_purchased', 'Product_Suppliers')\n",
      "('product_id|product_type_code|product_name|product_price', 'Products')\n",
      "('staff_id|staff_gender|staff_name', 'Staff')\n",
      "('staff_id|department_id|date_assigned_from|job_title_code|date_assigned_to', 'Staff_Department_Assignments')\n",
      "('supplier_id|address_id|date_from|date_to', 'Supplier_Addresses')\n",
      "('supplier_id|supplier_name|supplier_phone', 'Suppliers')\n"
     ]
    }
   ],
   "source": [
    "new_meta = meta.groupby(['table_name'])['col_name'].apply(list).reset_index()\n",
    "new_meta = new_meta.set_index('table_name')\n",
    "\n",
    "tpc_ds = []\n",
    "for idx, row in new_meta.iterrows():\n",
    "    v = (('|').join(row.values[0]), idx)\n",
    "    print(v)\n",
    "    tpc_ds.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('address_id|address_details', 'Addresses')\n",
      "Adding table Addresses with schema address_id|address_details\n",
      "Writing questions to ./data/rag/questionListAddresses.json, with schema address_id|address_details, with table name Addresses and answer • 1. What is the total number of unique addresses in the system?\n",
      "\n",
      "• 2. Which addresses have specific details or characteristics (e.g., residential, commercial, located in a particular city or region)?\n",
      "\n",
      "• 3. How many addresses are associated with a particular customer or entity?\n",
      "\n",
      "• 4. Can you provide a list of addresses that meet certain criteria (e.g., within a specific zip code range, containing a specific keyword in the address details)?\n",
      "\n",
      "• 5. What is the distribution of addresses across different geographic regions or areas?\n",
      "\n",
      "• 6. Which addresses have been recently added or updated in the system?\n",
      "\n",
      "• 7. How can I identify duplicate or potentially redundant address entries?\n",
      "\n",
      "• 8. Can you provide a summary of address details for a specific subset of addresses (e.g., addresses associated with a particular customer segment or business unit)?\n",
      "\n",
      "• 9. What is the typical format or structure of the address details field, and how can I extract specific components (e.g., street name, city, state) from it?\n",
      "\n",
      "• 10. Which addresses have incomplete or missing details, and how can I identify them for further investigation or data enrichment?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('customer_id|address_id|date_from|date_to', 'Customer_Addresses')\n",
      "Adding table Customer_Addresses with schema customer_id|address_id|date_from|date_to\n",
      "Writing questions to ./data/rag/questionListCustomer_Addresses.json, with schema customer_id|address_id|date_from|date_to, with table name Customer_Addresses and answer 1. What is the total number of unique customers in the system?\n",
      "2. Which customers have had multiple addresses associated with their account?\n",
      "3. How many customers have had a change in their address during a specific time period?\n",
      "4. Can you identify the customers who have had the longest-lasting address association?\n",
      "5. What is the distribution of address changes across different customer segments or demographics?\n",
      "6. Which customers have had the most frequent address changes over time?\n",
      "7. How does the frequency of address changes vary across different geographic regions?\n",
      "8. Can you identify any patterns or trends in the timing of address changes (e.g., seasonal, annual, etc.)?\n",
      "9. What is the average duration of an address association for customers in a particular industry or business sector?\n",
      "10. Which customers have had address associations spanning multiple years or decades?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('order_id|customer_id|order_status_code|order_date', 'Customer_Orders')\n",
      "Adding table Customer_Orders with schema order_id|customer_id|order_status_code|order_date\n",
      "Writing questions to ./data/rag/questionListCustomer_Orders.json, with schema order_id|customer_id|order_status_code|order_date, with table name Customer_Orders and answer 1. What is the total number of orders placed by each customer?\n",
      "2. Which customers have placed orders with a specific order status (e.g., pending, shipped, canceled)?\n",
      "3. How many orders were placed on a particular date or within a specific date range?\n",
      "4. Can you identify customers who have placed multiple orders within a given time period?\n",
      "5. What is the distribution of order statuses across all orders?\n",
      "6. Which customers have the highest number of orders placed?\n",
      "7. How does the order volume vary over time (e.g., by month, quarter, or year)?\n",
      "8. Can you determine the average time between order placement and order status update for each customer?\n",
      "9. What is the longest duration between order placement and order status update across all orders?\n",
      "10. Which customers have orders that have been in a particular status for an extended period?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('customer_id|payment_method_code|customer_code|customer_name|customer_address|customer_phone|customer_email', 'Customers')\n",
      "Adding table Customers with schema customer_id|payment_method_code|customer_code|customer_name|customer_address|customer_phone|customer_email\n",
      "Writing questions to ./data/rag/questionListCustomers.json, with schema customer_id|payment_method_code|customer_code|customer_name|customer_address|customer_phone|customer_email, with table name Customers and answer 1. What payment methods are accepted from customers?\n",
      "2. How can customers be identified uniquely?\n",
      "3. Which customers have provided their contact information?\n",
      "4. What are the different types of customer codes used?\n",
      "5. Can customers' physical addresses be determined from the data?\n",
      "6. How can customers be categorized based on their payment method and customer code?\n",
      "7. Which customers have provided both phone numbers and email addresses?\n",
      "8. What is the relationship between customer codes and customer names?\n",
      "9. Can customers' preferred communication channels be inferred from the available data?\n",
      "10. How can customers be grouped based on their geographic locations?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('dept_store_chain_id|dept_store_chain_name', 'Department_Store_Chain')\n",
      "Adding table Department_Store_Chain with schema dept_store_chain_id|dept_store_chain_name\n",
      "Writing questions to ./data/rag/questionListDepartment_Store_Chain.json, with schema dept_store_chain_id|dept_store_chain_name, with table name Department_Store_Chain and answer 1. What is the total number of department store chains in the database?\n",
      "2. Which department store chains have the longest names?\n",
      "3. How many department store chains have names starting with a specific letter or word?\n",
      "4. Can you provide a list of department store chains sorted alphabetically by their names?\n",
      "5. What is the distribution of department store chains based on the length of their names?\n",
      "6. Which department store chains have names that contain specific words or phrases?\n",
      "7. How many department store chains have unique names (i.e., no duplicates)?\n",
      "8. Can you identify any patterns or trends in the naming conventions of department store chains?\n",
      "9. What is the average length of department store chain names in the database?\n",
      "10. Which department store chains have names that are palindromes or contain palindromic sequences?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('dept_store_id|dept_store_chain_id|store_name|store_address|store_phone|store_email', 'Department_Stores')\n",
      "Adding table Department_Stores with schema dept_store_id|dept_store_chain_id|store_name|store_address|store_phone|store_email\n",
      "Writing questions to ./data/rag/questionListDepartment_Stores.json, with schema dept_store_id|dept_store_chain_id|store_name|store_address|store_phone|store_email, with table name Department_Stores and answer 1. What is the unique identifier for each department store location?\n",
      "2. Which department store chain does a particular store location belong to?\n",
      "3. What is the name of a specific department store location?\n",
      "4. What is the physical address of a particular department store?\n",
      "5. How can a customer contact a specific department store location by phone?\n",
      "6. Can customers reach out to a department store via email, and if so, what is the email address?\n",
      "7. Which department store locations are part of the same chain?\n",
      "8. How many department store chains are represented in the data?\n",
      "9. What is the geographic distribution of the department store locations?\n",
      "10. Can the data be used to identify the closest department store location to a given address?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('department_id|dept_store_id|department_name', 'Departments')\n",
      "Adding table Departments with schema department_id|dept_store_id|department_name\n",
      "Writing questions to ./data/rag/questionListDepartments.json, with schema department_id|dept_store_id|department_name, with table name Departments and answer 1. What is the total number of distinct departments across all stores?\n",
      "2. Which stores have the highest and lowest number of departments?\n",
      "3. How many departments have a specific name (e.g., \"Electronics\" or \"Clothing\")?\n",
      "4. Can you identify the stores that have a department with a particular name?\n",
      "5. What is the distribution of department names across all stores?\n",
      "6. Which stores have departments with similar or related names?\n",
      "7. How many stores have a unique set of department names compared to other stores?\n",
      "8. Can you determine if there are any patterns or trends in the department names across different stores?\n",
      "9. What is the most common and least common department name across all stores?\n",
      "10. Which stores have the most diverse range of department names?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('order_item_id|order_id|product_id', 'Order_Items')\n",
      "Adding table Order_Items with schema order_item_id|order_id|product_id\n",
      "Writing questions to ./data/rag/questionListOrder_Items.json, with schema order_item_id|order_id|product_id, with table name Order_Items and answer • 1. What is the total number of unique orders placed?\n",
      "• 2. Which products were included in a specific order?\n",
      "• 3. How many times was a particular product ordered?\n",
      "• 4. Can we identify the most frequently ordered products?\n",
      "• 5. What is the distribution of order sizes (number of items per order)?\n",
      "• 6. Which orders contained multiple instances of the same product?\n",
      "• 7. How can we identify potential duplicate or erroneous order entries?\n",
      "• 8. What is the relationship between order identifiers and product identifiers?\n",
      "• 9. Can we determine the sequence or chronology of orders placed?\n",
      "• 10. Which products were ordered together most frequently?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('product_id|supplier_id|date_supplied_from|date_supplied_to|total_amount_purchased|total_value_purchased', 'Product_Suppliers')\n",
      "Adding table Product_Suppliers with schema product_id|supplier_id|date_supplied_from|date_supplied_to|total_amount_purchased|total_value_purchased\n",
      "Writing questions to ./data/rag/questionListProduct_Suppliers.json, with schema product_id|supplier_id|date_supplied_from|date_supplied_to|total_amount_purchased|total_value_purchased, with table name Product_Suppliers and answer 1. What products were supplied by each vendor, and what were the total quantities and values purchased for each product-vendor combination during the specified time periods?\n",
      "\n",
      "2. Which vendors supplied the highest total value of products, and what were the corresponding products and time periods?\n",
      "\n",
      "3. How did the total quantities and values of products purchased from each vendor vary over different time periods?\n",
      "\n",
      "4. Can you identify any seasonal patterns or trends in the supply of specific products from particular vendors based on the date ranges?\n",
      "\n",
      "5. What were the most recent and earliest dates when products were supplied by each vendor, and how did the total amounts and values differ between those dates?\n",
      "\n",
      "6. Which products had the highest total value purchased across all vendors, and which vendors supplied those products during the specified time periods?\n",
      "\n",
      "7. How did the average value per unit of each product vary across different vendors and time periods?\n",
      "\n",
      "8. Can you determine if there were any gaps or overlaps in the supply of products from different vendors based on the date ranges?\n",
      "\n",
      "9. What were the top combinations of products and vendors in terms of total value purchased, and how did these combinations change over different time periods?\n",
      "\n",
      "10. Which vendors consistently supplied products over extended periods, and what were the total quantities and values purchased from them during those periods?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('product_id|product_type_code|product_name|product_price', 'Products')\n",
      "Adding table Products with schema product_id|product_type_code|product_name|product_price\n",
      "Writing questions to ./data/rag/questionListProducts.json, with schema product_id|product_type_code|product_name|product_price, with table name Products and answer • 1. What are the different types of products offered and their corresponding prices?\n",
      "\n",
      "• 2. Which products have the highest and lowest prices in the catalog?\n",
      "\n",
      "• 3. How many distinct product categories are available, and what are their respective product counts?\n",
      "\n",
      "• 4. Can customers filter or sort products based on their type or price range?\n",
      "\n",
      "• 5. What is the price distribution of products across different categories?\n",
      "\n",
      "• 6. Which product category has the most expensive and least expensive offerings?\n",
      "\n",
      "• 7. How frequently are new products added or existing ones updated in the catalog?\n",
      "\n",
      "• 8. Can customers search for products using keywords or specific criteria?\n",
      "\n",
      "• 9. What are the most popular and best-selling product types based on sales data?\n",
      "\n",
      "• 10. How do the product prices compare to industry averages or competitors' offerings?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('staff_id|staff_gender|staff_name', 'Staff')\n",
      "Adding table Staff with schema staff_id|staff_gender|staff_name\n",
      "Writing questions to ./data/rag/questionListStaff.json, with schema staff_id|staff_gender|staff_name, with table name Staff and answer • 1. What are the different genders represented among the staff members?\n",
      "\n",
      "• 2. Which staff members have the longest names?\n",
      "\n",
      "• 3. How many unique staff members are listed in the table?\n",
      "\n",
      "• 4. Can you provide a breakdown of the staff members by gender?\n",
      "\n",
      "• 5. What is the most common gender among the staff members?\n",
      "\n",
      "• 6. Which staff members have names that start with a particular letter?\n",
      "\n",
      "• 7. How many staff members have names that contain a specific substring?\n",
      "\n",
      "• 8. Can you identify any staff members with gender-neutral names?\n",
      "\n",
      "• 9. What is the distribution of staff members based on the length of their names?\n",
      "\n",
      "• 10. Which staff members have names that are palindromes?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('staff_id|department_id|date_assigned_from|job_title_code|date_assigned_to', 'Staff_Department_Assignments')\n",
      "Adding table Staff_Department_Assignments with schema staff_id|department_id|date_assigned_from|job_title_code|date_assigned_to\n",
      "Writing questions to ./data/rag/questionListStaff_Department_Assignments.json, with schema staff_id|department_id|date_assigned_from|job_title_code|date_assigned_to, with table name Staff_Department_Assignments and answer 1. What employees are assigned to which departments, and what are their job titles?\n",
      "2. How many different departments does each employee work in over time?\n",
      "3. Which employees have been assigned to multiple departments, and what were the start and end dates of those assignments?\n",
      "4. Can you identify employees who have held the same job title across different department assignments?\n",
      "5. What is the longest duration an employee has been assigned to a particular department and job title?\n",
      "6. Which departments have had the most employee assignments over a given time period?\n",
      "7. How frequently do employees change departments or job titles within the organization?\n",
      "8. Can you track the career progression of an employee based on their department and job title assignments over time?\n",
      "9. What is the typical tenure of an employee in a particular department or job title?\n",
      "10. Which departments have experienced the highest turnover or reassignment of employees?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('supplier_id|address_id|date_from|date_to', 'Supplier_Addresses')\n",
      "Adding table Supplier_Addresses with schema supplier_id|address_id|date_from|date_to\n",
      "Writing questions to ./data/rag/questionListSupplier_Addresses.json, with schema supplier_id|address_id|date_from|date_to, with table name Supplier_Addresses and answer 1. What suppliers have had multiple addresses over time?\n",
      "2. Which suppliers have had the same address for the longest period?\n",
      "3. How many suppliers have changed their address within a specific date range?\n",
      "4. When did a particular supplier's address change?\n",
      "5. Can we identify suppliers who have relocated to a different region or country based on their address history?\n",
      "6. What is the most common duration for a supplier to maintain the same address?\n",
      "7. Which suppliers have had the highest number of address changes?\n",
      "8. How can we determine if a supplier's address change was temporary or permanent?\n",
      "9. Can we analyze the frequency of address changes for suppliers in different industries or regions?\n",
      "10. What insights can be gained from the patterns of address changes among suppliers over time?.\n",
      "\n",
      "\n",
      "-------------------\n",
      "('supplier_id|supplier_name|supplier_phone', 'Suppliers')\n",
      "Adding table Suppliers with schema supplier_id|supplier_name|supplier_phone\n",
      "Writing questions to ./data/rag/questionListSuppliers.json, with schema supplier_id|supplier_name|supplier_phone, with table name Suppliers and answer • 1. What are the names of all the suppliers in the database?\n",
      "• 2. Which suppliers have a phone number listed?\n",
      "• 3. How many unique suppliers are there in the database?\n",
      "• 4. Can you provide a list of suppliers sorted alphabetically by their name?\n",
      "• 5. What is the longest supplier name in the database?\n",
      "• 6. Which supplier has the shortest name?\n",
      "• 7. How many suppliers have a phone number that starts with a specific area code?\n",
      "• 8. Can you identify any suppliers with duplicate or missing phone numbers?\n",
      "• 9. What is the most common prefix or pattern in the supplier phone numbers?\n",
      "• 10. Which suppliers have phone numbers with a specific number of digits?.\n",
      "\n",
      "\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for x in tpc_ds:\n",
    "    print(x)\n",
    "    add_new_table(\n",
    "        schema=x[0], \n",
    "        table_name=x[1],\n",
    "        is_incremental=True, \n",
    "        bedrock_embeddings=bedrock_embeddings\n",
    "    )\n",
    "    print('-------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "def get_cfn_outputs(stackname, cfn):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)[\"Stacks\"][0][\"Outputs\"]:\n",
    "        outputs[output[\"OutputKey\"]] = output[\"OutputValue\"]\n",
    "    return outputs\n",
    "\n",
    "region_name = \"us-west-2\"\n",
    "\n",
    "cfn = boto3.client(\"cloudformation\", region_name)\n",
    "kms = boto3.client(\"secretsmanager\", region_name)\n",
    "\n",
    "stackname = \"opensearch-workshop\"\n",
    "cfn_outputs = get_cfn_outputs(stackname, cfn)\n",
    "\n",
    "aos_credentials = json.loads(\n",
    "    kms.get_secret_value(SecretId=cfn_outputs[\"OpenSearchSecret\"])[\"SecretString\"]\n",
    ")\n",
    "\n",
    "aos_host = cfn_outputs[\"OpenSearchDomainEndpoint\"]\n",
    "aos_host\n",
    "\n",
    "auth = (aos_credentials[\"username\"], aos_credentials[\"password\"])\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts=[{\"host\": aos_host, \"port\": 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = {\n",
    "    \"description\": \"Text to Sql Task - OpenSearch-cohere-060124084807\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": model_id,\n",
    "                \"field_map\": {\n",
    "                    \"text\": \"vector_field\",\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "pipeline_id = \"text2sql_meta_data\"\n",
    "# aos_client.ingest.delete_pipeline(id=pipeline_id)\n",
    "aos_client.ingest.put_pipeline(id=pipeline_id, body=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DTDeTJAB3Hj2edbFglKU'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "search_model = {\"query\": {\"match\": {\"name\": \"OpenSearch-Cohere\"}}, \"size\": 10}\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://\" + aos_host + \"/_plugins/_ml/models/_search\", auth=auth, json=search_model\n",
    ")\n",
    "model_info = json.loads(response.text)\n",
    "model_id = model_info[\"hits\"][\"hits\"][0][\"_id\"]\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = {\n",
    "    \"description\": \"Text to Sql Task - OpenSearch-cohere-060124084807\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": model_id,\n",
    "                \"field_map\": {\n",
    "                    \"text\": \"vector_field\",\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "pipeline_id = \"text2sql_meta_data\"\n",
    "# aos_client.ingest.delete_pipeline(id=pipeline_id)\n",
    "aos_client.ingest.put_pipeline(id=pipeline_id, body=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'rag_semantic_ver4'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"rag_semantic_ver4\"\n",
    "\n",
    "# aos_client.indices.delete(index=index_name)\n",
    "\n",
    "rag_semantic = {\n",
    "    \"settings\": {\n",
    "        \"max_result_window\": 15000,\n",
    "        \"analysis\": {\"analyzer\": {\"analysis-nori\": {\"type\": \"nori\", \"stopwords\": \"_korean_\"}}},\n",
    "        \"index.knn\": True,\n",
    "        \"default_pipeline\": pipeline_id,\n",
    "        \"index.knn.space_type\": \"l2\",\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"tableName\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"question\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"tableSchema\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
    "            },\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                \"method\": {\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"faiss\"},\n",
    "                \"store\": True,\n",
    "            },\n",
    "\n",
    "        }\n",
    "    },\n",
    "}\n",
    "aos_client.indices.create(index=index_name, body=rag_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from opensearchpy import helpers\n",
    "\n",
    "def _generate_data():\n",
    "    for doc in docs:\n",
    "        yield {\"_index\": index_name, \"_source\": doc}\n",
    "\n",
    "succeeded = []\n",
    "failed = []\n",
    "\n",
    "json_files = os.listdir('./data/rag')\n",
    "for p in json_files:\n",
    "    with open(f\"./data/rag/{p}\", 'rb') as ofp:\n",
    "        docs = json.load(ofp)\n",
    "\n",
    "    for success, item in helpers.parallel_bulk(\n",
    "        aos_client, actions=_generate_data(), chunk_size=10, thread_count=1, queue_size=1\n",
    "    ):\n",
    "        if success:\n",
    "            succeeded.append(item)\n",
    "        else:\n",
    "            failed.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 140, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Refresh the index to make the changes visible\n",
    "aos_client.indices.refresh(index=index_name)\n",
    "\n",
    "count = aos_client.count(index=index_name)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keyword_search(query_text):\n",
    "    query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": {\"excludes\": [\"text\", \"vector_field\"]},\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query_text,\n",
    "                \"fields\": [\"tableName\", \"question\", \"tableSchema\"],\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, body=query)\n",
    "\n",
    "    query_result = []\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        row = [\n",
    "            hit[\"_score\"],\n",
    "            hit[\"_source\"][\"tableName\"],\n",
    "            hit[\"_source\"][\"question\"],\n",
    "            hit[\"_source\"][\"tableSchema\"],            \n",
    "        ]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(\n",
    "        data=query_result, columns=[\"_score\", \"tableName\", \"question\", \"tableSchema\"]\n",
    "    )\n",
    "    display(query_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def semantic_search(query_text):\n",
    "    query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": {\"excludes\": [\"text\", \"vector_field\"]},\n",
    "        \"query\": {\n",
    "            \"neural\": {\"vector_field\": {\"query_text\": query_text, \"model_id\": model_id, \"k\": 10}},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, body=query)\n",
    "\n",
    "    query_result = []\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        row = [\n",
    "            hit[\"_score\"],\n",
    "            hit[\"_source\"][\"tableName\"],\n",
    "            hit[\"_source\"][\"question\"],\n",
    "            hit[\"_source\"][\"tableSchema\"],            \n",
    "        ]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(\n",
    "        data=query_result, columns=[\"_score\", \"tableName\", \"question\", \"tableSchema\"]\n",
    "    )\n",
    "    display(query_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tableName</th>\n",
       "      <th>question</th>\n",
       "      <th>tableSchema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.621939</td>\n",
       "      <td>Customers</td>\n",
       "      <td>What is the relationship between customer cod...</td>\n",
       "      <td>customer_id|payment_method_code|customer_code|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.991430</td>\n",
       "      <td>Department_Stores</td>\n",
       "      <td>Can customers reach out to a department store...</td>\n",
       "      <td>dept_store_id|dept_store_chain_id|store_name|s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.698285</td>\n",
       "      <td>Customers</td>\n",
       "      <td>What are the different types of customer code...</td>\n",
       "      <td>customer_id|payment_method_code|customer_code|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.661865</td>\n",
       "      <td>Customers</td>\n",
       "      <td>Which customers have provided both phone numb...</td>\n",
       "      <td>customer_id|payment_method_code|customer_code|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.353212</td>\n",
       "      <td>Customers</td>\n",
       "      <td>How can customers be categorized based on the...</td>\n",
       "      <td>customer_id|payment_method_code|customer_code|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.215492</td>\n",
       "      <td>Customer_Orders</td>\n",
       "      <td>What is the total number of orders placed by ...</td>\n",
       "      <td>order_id|customer_id|order_status_code|order_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.151422</td>\n",
       "      <td>Customer_Addresses</td>\n",
       "      <td>What is the distribution of address changes a...</td>\n",
       "      <td>customer_id|address_id|date_from|date_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.143315</td>\n",
       "      <td>Addresses</td>\n",
       "      <td>• 3. How many addresses are associated with a ...</td>\n",
       "      <td>address_id|address_details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.143315</td>\n",
       "      <td>Department_Stores</td>\n",
       "      <td>How can a customer contact a specific departm...</td>\n",
       "      <td>dept_store_id|dept_store_chain_id|store_name|s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.896213</td>\n",
       "      <td>Customer_Orders</td>\n",
       "      <td>Can you determine the average time between or...</td>\n",
       "      <td>order_id|customer_id|order_status_code|order_date</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _score           tableName  \\\n",
       "0  4.621939           Customers   \n",
       "1  2.991430   Department_Stores   \n",
       "2  2.698285           Customers   \n",
       "3  2.661865           Customers   \n",
       "4  2.353212           Customers   \n",
       "5  2.215492     Customer_Orders   \n",
       "6  2.151422  Customer_Addresses   \n",
       "7  2.143315           Addresses   \n",
       "8  2.143315   Department_Stores   \n",
       "9  1.896213     Customer_Orders   \n",
       "\n",
       "                                            question  \\\n",
       "0   What is the relationship between customer cod...   \n",
       "1   Can customers reach out to a department store...   \n",
       "2   What are the different types of customer code...   \n",
       "3   Which customers have provided both phone numb...   \n",
       "4   How can customers be categorized based on the...   \n",
       "5   What is the total number of orders placed by ...   \n",
       "6   What is the distribution of address changes a...   \n",
       "7  • 3. How many addresses are associated with a ...   \n",
       "8   How can a customer contact a specific departm...   \n",
       "9   Can you determine the average time between or...   \n",
       "\n",
       "                                         tableSchema  \n",
       "0  customer_id|payment_method_code|customer_code|...  \n",
       "1  dept_store_id|dept_store_chain_id|store_name|s...  \n",
       "2  customer_id|payment_method_code|customer_code|...  \n",
       "3  customer_id|payment_method_code|customer_code|...  \n",
       "4  customer_id|payment_method_code|customer_code|...  \n",
       "5  order_id|customer_id|order_status_code|order_date  \n",
       "6           customer_id|address_id|date_from|date_to  \n",
       "7                         address_id|address_details  \n",
       "8  dept_store_id|dept_store_chain_id|store_name|s...  \n",
       "9  order_id|customer_id|order_status_code|order_date  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_text =  \"customer email\"\n",
    "keyword_search(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>tableName</th>\n",
       "      <th>question</th>\n",
       "      <th>tableSchema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_score, tableName, question, tableSchema]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "semantic_search(query_text)\n",
    "# print(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_db = FAISS.load_local(DB_FAISS_PATH, bedrock_embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"고객 이메일 주소가 적제된 테이블을 알려줘\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Can customers reach out to a department store via email, and if so, what is the email address?\n",
      " How can customers be categorized based on their payment method and customer code?\n",
      " How can customers be grouped based on their location or address?\n",
      " Which customers have provided their contact information?\n"
     ]
    }
   ],
   "source": [
    "schema =  {}\n",
    "\n",
    "results_with_scores = question_db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(doc.metadata['question'])\n",
    "    schema[doc.metadata['tableName']] = doc.metadata['tableSchema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Department_Stores': 'dept_store_id|dept_store_chain_id|store_name|store_address|store_phone|store_email',\n",
       " 'Customers': 'customer_id|payment_method_code|customer_code|customer_name|customer_address|customer_phone|customer_email'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
