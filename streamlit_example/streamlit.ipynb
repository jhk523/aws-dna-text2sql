{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51c4957-1bf8-4243-8e6d-24b555e56880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import streamlit as st  # ëª¨ë“  streamlit ëª…ë ¹ì€ \"st\" aliasë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "import bedrock as glib  # ë¡œì»¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìŠ¤í¬ë¦½íŠ¸ì— ëŒ€í•œ ì°¸ì¡°\n",
    "from langchain.callbacks import StreamlitCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86e6966-7002-466a-8a9f-7def1b761b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 05:30:39.824 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-06-26 05:30:39.825 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "##################### Functions ########################\n",
    "def parse_image(metadata, tag):\n",
    "    if tag in metadata: \n",
    "        st.image(base64.b64decode(metadata[tag]))\n",
    "\n",
    "def parse_table(metadata, tag):\n",
    "    if tag in metadata:\n",
    "        st.markdown(metadata[tag], unsafe_allow_html=True)\n",
    "\n",
    "def parse_metadata(metadata):\n",
    "    # Image, Table ì´ ìˆì„ ê²½ìš° íŒŒì‹±í•´ ì¶œë ¥\n",
    "    category = \"None\"\n",
    "    if \"category\" in metadata:\n",
    "        category = metadata[\"category\"]\n",
    "        if category == \"Table\":\n",
    "            # parse_table(metadata, \"text_as_html\") # í…Œì´ë¸” htmlì€ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´\n",
    "            parse_image(metadata, \"image_base64\")\n",
    "        elif category == \"Image\":\n",
    "            parse_image(metadata, \"image_base64\")\n",
    "        else: \n",
    "            pass\n",
    "    st.markdown(' - - - ')\n",
    "\n",
    "# 'Separately' ì˜µì…˜ ì„ íƒ ì‹œ ë‚˜ì˜¤ëŠ” ì¤‘ê°„ Contextë¥¼ íƒ­ í˜•íƒœë¡œ ë³´ì—¬ì£¼ëŠ” UI\n",
    "def show_context_with_tab(contexts):\n",
    "    tab_category = [\"Semantic\", \"Keyword\", \"Without Reranker\", \"Similar Docs\"]\n",
    "    tab_contents = {\n",
    "        tab_category[0]: [],\n",
    "        tab_category[1]: [],\n",
    "        tab_category[2]: [],\n",
    "        tab_category[3]: []\n",
    "    }\n",
    "    for i, contexts_by_doctype in enumerate(contexts):\n",
    "        tab_contents[tab_category[i]].append(contexts_by_doctype)\n",
    "    tabs = st.tabs(tab_category)\n",
    "    for i, tab in enumerate(tabs):\n",
    "        category = tab_category[i]\n",
    "        with tab:\n",
    "            for contexts_by_doctype in tab_contents[category]:\n",
    "                for context in contexts_by_doctype:\n",
    "                    st.markdown('##### `ì •í™•ë„`: {}'.format(context[\"score\"]))\n",
    "                    for line in context[\"lines\"]:\n",
    "                        st.write(line)\n",
    "                    parse_metadata(context[\"meta\"])\n",
    "                    ### TODO: parent_docs ì„ íƒ ì‹œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ fix\n",
    "                    \n",
    "# 'All at once' ì˜µì…˜ ì„ íƒ ì‹œ 4ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê²°ê³¼ í‘œì‹œí•˜ëŠ” UI\n",
    "# TODO: HyDE, RagFusion ì¶”ê°€ ë…¼ì˜ í•„ìš”\n",
    "def show_answer_with_multi_columns(answers): \n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    with col1:\n",
    "        st.markdown('''### `Lexical search` ''')\n",
    "        st.write(answers[0])\n",
    "    with col2:\n",
    "        st.markdown('''### `Semantic search` ''')\n",
    "        st.write(answers[1])\n",
    "    with col3:\n",
    "        st.markdown('''### + `Reranker` ''')\n",
    "        st.write(answers[2])\n",
    "    with col4:\n",
    "        st.markdown('''### + `Parent_docs` ''') \n",
    "        st.write(answers[3])\n",
    "\n",
    "####################### Application ###############################\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"AWS Q&A Bot with Advanced RAG!\")  # page ì œëª©\n",
    "\n",
    "st.markdown('''- This chatbot is implemented using Amazon Bedrock Claude v3 Sonnet.''')\n",
    "st.markdown('''- Integrated advanced RAG technology: **Hybrid Search, ReRanker, and Parent Document, HyDE, Rag Fusion** techniques.''')\n",
    "st.markdown('''- The original data is stored in Amazon OpenSearch, and the embedding model utilizes Amazon Titan.''')\n",
    "st.markdown('''\n",
    "            - You can find the source code in \n",
    "            [this Github](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot/04_web_ui)\n",
    "            ''')\n",
    "# Store the initial value of widgets in session state\n",
    "if \"showing_option\" not in st.session_state:\n",
    "    st.session_state.showing_option = \"Separately\"\n",
    "if \"search_mode\" not in st.session_state:\n",
    "    st.session_state.search_mode = \"Hybrid search\"\n",
    "if \"hyde_or_ragfusion\" not in st.session_state:\n",
    "    st.session_state.hyde_or_ragfusion = \"None\"\n",
    "disabled = st.session_state.showing_option==\"All at once\"\n",
    "\n",
    "with st.sidebar: # Sidebar ëª¨ë¸ ì˜µì…˜\n",
    "    with st.container(border=True):\n",
    "        st.radio(\n",
    "            \"Choose UI between 2 options:\",\n",
    "            [\"Separately\", \"All at once\"],\n",
    "            captions = [\"ì•„ë˜ì—ì„œ ì„¤ì •í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ í•˜ë‚˜ì˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ì¶œë©ë‹ˆë‹¤.\", \"ì—¬ëŸ¬ ì˜µì…˜ë“¤ì„ í•œ í™”ë©´ì—ì„œ í•œêº¼ë²ˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"],\n",
    "            key=\"showing_option\",\n",
    "        )\n",
    "    st.markdown('''### Set parameters for your Bot ğŸ‘‡''')\n",
    "\n",
    "    with st.container(border=True):\n",
    "        search_mode = st.radio(\n",
    "            \"Choose a search mode:\",\n",
    "            [\"Lexical search\", \"Semantic search\", \"Hybrid search\"],\n",
    "            captions = [\n",
    "                \"í‚¤ì›Œë“œì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\",\n",
    "                \"í‚¤ì›Œë“œì˜ ì¼ì¹˜ ì—¬ë¶€ë³´ë‹¤ëŠ” ë¬¸ë§¥ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ì— ê¸°ë°˜í•´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\", \n",
    "                \"ì•„ë˜ì˜ Alpha ê°’ì„ ì¡°ì •í•˜ì—¬ Lexical/Semantic searchì˜ ë¹„ìœ¨ì„ ì¡°ì •í•©ë‹ˆë‹¤.\"\n",
    "                ],\n",
    "            key=\"search_mode\",\n",
    "            disabled=disabled\n",
    "            )\n",
    "        alpha = st.slider('Alpha value for Hybrid search â¬‡ï¸', 0.0, 1.0, 0.51, \n",
    "                          disabled=st.session_state.search_mode != \"Hybrid search\",\n",
    "                          help=\"\"\"Alpha=0.0 ì´ë©´ Lexical search,   \\nAlpha=1.0 ì´ë©´ Semantic search ì…ë‹ˆë‹¤.\"\"\"\n",
    "                          )\n",
    "        if search_mode == \"Lexical search\":\n",
    "            alpha = 0.0\n",
    "        elif search_mode == \"Semantic search\":\n",
    "            alpha = 1.0\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        reranker = st.toggle(\"Reranker\", \n",
    "                             help=\"\"\"ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬í‰ê°€í•˜ì—¬ ìˆœìœ„ë¥¼ ì¬ì¡°ì •í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.   \n",
    "                             ë¬¸ë§¥ ì •ë³´ì™€ ì§ˆì˜ ê´€ë ¨ì„±ì„ ê³ ë ¤í•˜ì—¬ ì í•©í•œ ê²°ê³¼ë¥¼ ìƒìœ„ì— ì˜¬ë¦½ë‹ˆë‹¤.\"\"\",\n",
    "                             disabled=disabled)\n",
    "    with col2:\n",
    "        parent = st.toggle(\"Parent Docs\", \n",
    "                           help=\"\"\"ë‹µë³€ ìƒì„± ëª¨ë¸ì´ ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•  ë•Œ ì°¸ì¡°í•œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ í‘œì‹œí•˜ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤.\"\"\", \n",
    "                           disabled=disabled)\n",
    "\n",
    "    with st.container(border=True):\n",
    "        hyde_or_ragfusion = st.radio(\n",
    "            \"Choose a RAG option:\",\n",
    "            [\"None\", \"HyDE\", \"RAG-Fusion\"],\n",
    "            captions = [\n",
    "                \"\", \n",
    "                \"ë¬¸ì„œì™€ ì§ˆì˜ ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì„ë² ë”© ê¸°ë²•ì…ë‹ˆë‹¤. í•˜ì´í¼ë³¼ë¦­ ê³µê°„ì—ì„œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\", \n",
    "                \"ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ ëª¨ë¸ë¡œ, ê²€ìƒ‰ ëª¨ë“ˆì´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ê³  ìƒì„± ëª¨ë“ˆì´ ì´ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ë‘ ëª¨ë“ˆì˜ ì¶œë ¥ì„ ìœµí•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ë„ì¶œí•©ë‹ˆë‹¤.\"\n",
    "                ],\n",
    "            key=\"hyde_or_ragfusion\",\n",
    "            disabled=disabled\n",
    "            ) \n",
    "        hyde = hyde_or_ragfusion == \"HyDE\"\n",
    "        ragfusion = hyde_or_ragfusion == \"RAG-Fusion\"\n",
    "\n",
    "###### 1) 'Separately' ì˜µì…˜ ì„ íƒí•œ ê²½ìš° ######\n",
    "if st.session_state.showing_option == \"Separately\":\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = [\n",
    "            {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
    "        ]\n",
    "    # ì§€ë‚œ ë‹µë³€ ì¶œë ¥\n",
    "    for msg in st.session_state.messages:\n",
    "        # ì§€ë‚œ ë‹µë³€ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "        if msg[\"role\"] == \"assistant_context\": \n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.expander(\"Context í™•ì¸í•˜ê¸° â¬‡ï¸\"):\n",
    "                    show_context_with_tab(contexts=msg[\"content\"])\n",
    "                    \n",
    "        elif msg[\"role\"] == \"hyde_or_fusion\":\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.expander(\"ì¤‘ê°„ ë‹µë³€ í™•ì¸í•˜ê¸° â¬‡ï¸\"):\n",
    "                    msg[\"content\"]\n",
    "                    \n",
    "        elif msg[\"role\"] == \"assistant_column\":\n",
    "            # 'Separately' ì˜µì…˜ì¼ ê²½ìš° multi column ìœ¼ë¡œ ë³´ì—¬ì£¼ì§€ ì•Šê³  ì²« ë²ˆì§¸ ë‹µë³€ë§Œ ì¶œë ¥\n",
    "            st.chat_message(msg[\"role\"]).write(msg[\"content\"][0]) \n",
    "        else:\n",
    "            st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "    \n",
    "    # ìœ ì €ê°€ ì“´ chatì„ queryë¼ëŠ” ë³€ìˆ˜ì— ë‹´ìŒ\n",
    "    query = st.chat_input(\"Search documentation\")\n",
    "    if query:\n",
    "        # Sessionì— ë©”ì„¸ì§€ ì €ì¥\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        \n",
    "        # UIì— ì¶œë ¥\n",
    "        st.chat_message(\"user\").write(query)\n",
    "        \n",
    "        # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •\n",
    "        st_cb = StreamlitCallbackHandler(\n",
    "            st.chat_message(\"assistant\"), \n",
    "            collapse_completed_thoughts=True\n",
    "            )\n",
    "        # bedrock.pyì˜ invoke í•¨ìˆ˜ ì‚¬ìš©\n",
    "        response = glib.invoke(\n",
    "            query=query, \n",
    "            streaming_callback=st_cb, \n",
    "            parent=parent, \n",
    "            reranker=reranker,\n",
    "            hyde = hyde,\n",
    "            ragfusion = ragfusion,\n",
    "            alpha = alpha\n",
    "        )\n",
    "        # response ë¡œ ë©”ì„¸ì§€, ë§í¬, ë ˆí¼ëŸ°ìŠ¤(source_documents) ë°›ì•„ì˜¤ê²Œ ì„¤ì •ëœ ê²ƒì„ ë³€ìˆ˜ë¡œ ì €ì¥\n",
    "        answer = response[0]\n",
    "        contexts = response[1]\n",
    "        if hyde or ragfusion:\n",
    "            mid_answer = response[2]\n",
    "\n",
    "        # UI ì¶œë ¥\n",
    "        st.chat_message(\"assistant\").write(answer)\n",
    "        \n",
    "        \n",
    "        if hyde:\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.expander(\"HyDE ì¤‘ê°„ ìƒì„± ë‹µë³€ â¬‡ï¸\"):\n",
    "                    mid_answer\n",
    "            \n",
    "        if ragfusion:\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.expander(\"RAG-Fusion ì¤‘ê°„ ìƒì„± ì¿¼ë¦¬ â¬‡ï¸\"):\n",
    "                    mid_answer  \n",
    "        with st.chat_message(\"assistant\"): \n",
    "            with st.expander(\"ì •í™•ë„ ë³„ ì»¨í…ìŠ¤íŠ¸ ë³´ê¸° â¬‡ï¸\"):\n",
    "                show_context_with_tab(contexts)\n",
    "        \n",
    "        # Session ë©”ì„¸ì§€ ì €ì¥\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        \n",
    "        if hyde or ragfusion:\n",
    "            st.session_state.messages.append({\"role\": \"hyde_or_fusion\", \"content\": mid_answer})\n",
    "\n",
    "        st.session_state.messages.append({\"role\": \"assistant_context\", \"content\": contexts})\n",
    "        # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ\n",
    "        st_cb._complete_current_thought()\n",
    "\n",
    "###### 2) 'All at once' ì˜µì…˜ ì„ íƒí•œ ê²½ìš° ######\n",
    "else:\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = [\n",
    "            {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
    "        ]\n",
    "    # ì§€ë‚œ ë‹µë³€ ì¶œë ¥\n",
    "    for msg in st.session_state.messages:\n",
    "        if msg[\"role\"] == \"assistant_column\":\n",
    "            answers = msg[\"content\"]\n",
    "            show_answer_with_multi_columns(answers)\n",
    "        elif msg[\"role\"] == \"assistant_context\": \n",
    "            pass # 'All at once' ì˜µì…˜ ì„ íƒ ì‹œì—ëŠ” context ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠìŒ\n",
    "        else:\n",
    "            st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "    \n",
    "    # ìœ ì €ê°€ ì“´ chatì„ queryë¼ëŠ” ë³€ìˆ˜ì— ë‹´ìŒ\n",
    "    query = st.chat_input(\"Search documentation\")\n",
    "    if query:\n",
    "        # Sessionì— ë©”ì„¸ì§€ ì €ì¥\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        \n",
    "        # UIì— ì¶œë ¥\n",
    "        st.chat_message(\"user\").write(query)\n",
    "\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        with col1:\n",
    "            st.markdown('''### `Lexical search` ''')\n",
    "            st.markdown(\":green[: Alpha ê°’ì´ 0.0]ìœ¼ë¡œ, í‚¤ì›Œë“œì˜ ì •í™•í•œ ì¼ì¹˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” Lexical search ê²°ê³¼ì…ë‹ˆë‹¤.\")\n",
    "        with col2:\n",
    "            st.markdown('''### `Semantic search` ''')\n",
    "            st.markdown(\":green[: Alpha ê°’ì´ 1.0]ìœ¼ë¡œ, í‚¤ì›Œë“œ ì¼ì¹˜ ì—¬ë¶€ë³´ë‹¤ëŠ” ë¬¸ë§¥ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ì— ê¸°ë°˜í•œ Semantic search ê²°ê³¼ì…ë‹ˆë‹¤.\")\n",
    "        with col3:\n",
    "            st.markdown('''### + `Reranker` ''')\n",
    "            st.markdown(\"\"\": ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬í‰ê°€í•˜ì—¬ ìˆœìœ„ë¥¼ ì¬ì¡°ì •í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ë¬¸ë§¥ ì •ë³´ì™€ ì§ˆì˜ ê´€ë ¨ì„±ì„ ê³ ë ¤í•˜ì—¬ ì í•©í•œ ê²°ê³¼ë¥¼ ìƒìœ„ì— ì˜¬ë¦½ë‹ˆë‹¤.\n",
    "                        :green[Alpha ê°’ì€ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •í•˜ì‹  ê°’]ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.\"\"\")\n",
    "        with col4:\n",
    "            st.markdown('''### + `Parent Docs` ''')\n",
    "            st.markdown(\"\"\": ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•  ë•Œ ì°¸ì¡°í•˜ëŠ” ë¬¸ì„œ ì§‘í•©ì…ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ëª¨ë¸ì´ ì°¸ì¡°í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ì •ë³´ì˜ ì¶œì²˜ê°€ ë©ë‹ˆë‹¤.\n",
    "                        :green[Alpha ê°’ì€ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •í•˜ì‹  ê°’]ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.\"\"\")\n",
    "        \n",
    "        with col1:\n",
    "            # Streamlit callback handlerë¡œ bedrock streaming ë°›ì•„ì˜¤ëŠ” ì»¨í…Œì´ë„ˆ ì„¤ì •\n",
    "            st_cb = StreamlitCallbackHandler(\n",
    "                st.chat_message(\"assistant\"), \n",
    "                collapse_completed_thoughts=True\n",
    "                )\n",
    "            answer1 = glib.invoke(\n",
    "                query=query, \n",
    "                streaming_callback=st_cb, \n",
    "                parent=False, \n",
    "                reranker=False,\n",
    "                hyde = False,\n",
    "                ragfusion = False,\n",
    "                alpha = 0 # Lexical search\n",
    "                )[0]\n",
    "            st.write(answer1)\n",
    "            st_cb._complete_current_thought() # Thinkingì„ completeë¡œ ìˆ˜ë™ìœ¼ë¡œ ë°”ê¾¸ì–´ ì¤Œ\n",
    "        with col2:\n",
    "            st_cb = StreamlitCallbackHandler(\n",
    "                st.chat_message(\"assistant\"), \n",
    "                collapse_completed_thoughts=True\n",
    "                )\n",
    "            answer2 = glib.invoke(\n",
    "                query=query, \n",
    "                streaming_callback=st_cb, \n",
    "                parent=False, \n",
    "                reranker=False,\n",
    "                hyde = False,\n",
    "                ragfusion = False,\n",
    "                alpha = 1.0 # Semantic search\n",
    "                )[0]\n",
    "            st.write(answer2)\n",
    "            st_cb._complete_current_thought() \n",
    "        with col3:\n",
    "            st_cb = StreamlitCallbackHandler(\n",
    "                st.chat_message(\"assistant\"), \n",
    "                collapse_completed_thoughts=True\n",
    "                )\n",
    "            answer3 = glib.invoke(\n",
    "                query=query, \n",
    "                streaming_callback=st_cb, \n",
    "                parent=False, \n",
    "                reranker=True, # Add Reranker option\n",
    "                hyde = False,\n",
    "                ragfusion = False,\n",
    "                alpha = alpha # Hybrid search\n",
    "                )[0]\n",
    "            st.write(answer3)\n",
    "            st_cb._complete_current_thought() \n",
    "        with col4:\n",
    "            st_cb = StreamlitCallbackHandler(\n",
    "                st.chat_message(\"assistant\"), \n",
    "                collapse_completed_thoughts=True\n",
    "            )\n",
    "            answer4 = glib.invoke(\n",
    "                query=query, \n",
    "                streaming_callback=st_cb, \n",
    "                parent=True, # Add Parent_docs option\n",
    "                reranker=True, # Add Reranker option\n",
    "                hyde = False,\n",
    "                ragfusion = False,\n",
    "                alpha = alpha # Hybrid search\n",
    "                )[0]\n",
    "            st.write(answer4)\n",
    "            st_cb._complete_current_thought()\n",
    "\n",
    "        # Session ë©”ì„¸ì§€ ì €ì¥\n",
    "        answers = [answer1, answer2, answer3, answer4]\n",
    "        st.session_state.messages.append({\"role\": \"assistant_column\", \"content\": answers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866ee74-a34d-42a5-ae09-9e7b804d6d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
